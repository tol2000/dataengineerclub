@startuml Схема процесса

skinparam ComponentStyle uml2

' left to right direction
' top to bottom direction

centerheader
= Тема проекта: Загрузка, хранение и анализ публично доступной информации
endheader

legend top left

    Я решил создать проект - основу для построения хранения и анализа
    общедоступной информации
    Для примера взял rest api погоды (либо вики-стримы или информация по вакансиям)

    Цель проекта - построить максимально недорогую открытую систему
    для приема, хранения и анализа любой общедоступной информации
    из открытых (а, возможно, и закрытых) источников

    Компоненты и решения, ввиду ограниченного срока разработки, я решил использовать
    классические и известные мне с курсов.

    Система должна основываться на свободных, желательно open-source,
    в крайнем случае недорогих, но эффективных и распространенных решениях.

    Система должна быть способна к расширению и масштабированию
        - Масштабирование обеспечивается возможностью масштабирования
          испльзуемых компонентов
        - Расширение (добавление новых источников данных)
          обеспечивается наличием различных коннекторов в StreamSets и
          якорной моделью DWH серебряного слоя

    - Загрузка данных и управление заданиями обеспечивается при помощи **StreamSets**
        StreamSets обеспечивает загрузку данных с различных источников,
        выгрузку их в хранилище,
        а также работает как планировщик процессов
    - NoSql для хранения сырых данных - **apache hive**
    - Возможно, **spark+scala** для парсинга json и параллельной загрузки
      сырых данных в DWH серебряного слоя
    - RDBMS для якорной модели DWH - **Vertica**
      Решение, быть может, не полностью укладывается в рамки open-source
      и lowcost, но начальное решение до 1ТиБ бесплатное и, если
      организовать партицирование по году и предыдущие года просто удалять,
      оставляя только какую-то конечную аналитику (группировка по году),
      то можно уложиться в бесплатный размер, сохраняя возможность
      масштабирования, откузоустойчивость и возможность в любое время
      отменить удаление старых партиций и заново загрузить
      сырые данные из бронзового уровня (Hive).

    При создании системы я старался придерживаться некоторых идеологий
    DevOps, в частности, All As A Code, что потом очень хорошо ложится
    в любую VCS вроде git, поэтому описание проекта, схема и документация
    созданы в asciidoc+plantuml.

    При создании проекта, опять же из-за ограниченного времени разработки,
    я скорее всего не буду полностью реализовывать всю систему для
    всей загружаемой информации, а построю какой-то один бизнес-кейс
    для примера. Скажем, анализ среднесуточной температуры.

endlegend

cloud "Источник (rest API)" as cloud_source #LightBlue {
}

note right of cloud_source
    Внешние данные
    с какого-либо публичного источника
end note

Actor "Внешний\nПользователь" as extuser

frame "Хранилище\nтипа Data Lake" as frame_dlstor {

    frame "Витрины" as frame_dlstor_dm #Gold {
        frame "Представления" as views_dm {
            component report_1 [
                Представление1
            ]
            component report_2 [
                Представление2
            ]
        }
        component batch_dm_refresh [
            **Batch**
            ----
            Обновление отчетов
            ----
            Периодичность: 
        ]
    }

    frame "Обработанные данные" as frame_dlstor_stage #LightGreen {
        database "Реляционная БД\n" as db_stage #Pink {
            component anchor_model_dwh [
                Якорная модель хранилища
            ]
        }
        component batch_stage_refresh [
            **StreamSets**
            ----
            PipeLine SilverLayer
            Оперативное обновление stage-данных
        ]
    }

    frame "Сырые данные" as frame_dlstor_raw #LightGray {
        database "NoSql БД Типа Hive" as db_raw #Pink {
            component raw_data [
                Сырые данные
            ]
        }
        component batch_raw_load [
            **StreamSets**
            ----
            PipeLine BronzeLayer
            Загрузка сырых данных
        ]
    }

    cloud_source --> batch_raw_load
    batch_raw_load --> db_raw

    db_raw --> db_stage

    db_stage --> views_dm


}
@enduml