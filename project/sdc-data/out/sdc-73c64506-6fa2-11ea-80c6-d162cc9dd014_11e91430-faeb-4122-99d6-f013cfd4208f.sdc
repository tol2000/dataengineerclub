¡{"header":{"stageCreator":"HiveMetadata_01","sourceId":"Table Metadata Recorddd61cbae-9b33-4d1e-b4d3-aa2973f85950","stagesPath":"HiveMetadata_01","trackingId":"Table Metadata Recorddd61cbae-9b33-4d1e-b4d3-aa2973f85950::HiveMetadata_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HadoopFS_01","errorStageLabel":"Hadoop FS 1","errorCode":"AVRO_GENERATOR_03","errorMessage":"AVRO_GENERATOR_03 - Record 'Table Metadata Recorddd61cbae-9b33-4d1e-b4d3-aa2973f85950' is missing required header 'avroSchema'","errorTimestamp":1586686403017,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: AVRO_GENERATOR_03 - Record 'Table Metadata Recorddd61cbae-9b33-4d1e-b4d3-aa2973f85950' is missing required header 'avroSchema'\n\tat com.streamsets.pipeline.stage.destination.hdfs.HdfsTarget$1.run(HdfsTarget.java:118)\n\tat com.streamsets.pipeline.stage.destination.hdfs.HdfsTarget$1.run(HdfsTarget.java:100)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1835)\n\tat com.streamsets.pipeline.stage.destination.hdfs.HdfsTarget.write(HdfsTarget.java:100)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"2","dqpath":"/version","sqpath":"/version"},{"type":"STRING","value":"TABLE","dqpath":"/type","sqpath":"/type"},{"type":"STRING","value":"default","dqpath":"/database","sqpath":"/database"},{"type":"STRING","value":"weather_all","dqpath":"/table","sqpath":"/table"},{"type":"STRING","value":"/user/hive/warehouse/weather_all","dqpath":"/location","sqpath":"/location"},{"type":"STRING","value":"AVRO","dqpath":"/dataFormat","sqpath":"/dataFormat"},{"type":"LIST","value":[{"type":"LIST_MAP","value":[{"type":"STRING","value":"area","dqpath":"/columns[0]/name","sqpath":"/columns[0]/name"},{"type":"MAP","value":{"comment":{"type":"STRING","value":"","dqpath":"/columns[0]/typeInfo/comment","sqpath":"/columns[0]/typeInfo/comment"},"type":{"type":"STRING","value":"STRING","dqpath":"/columns[0]/typeInfo/type","sqpath":"/columns[0]/typeInfo/type"},"extraInfo":{"type":"MAP","value":{},"dqpath":"/columns[0]/typeInfo/extraInfo","sqpath":"/columns[0]/typeInfo/extraInfo"}},"dqpath":"/columns[0]/typeInfo","sqpath":"/columns[0]/typeInfo"}],"dqpath":"/columns[0]","sqpath":"/columns[0]"},{"type":"LIST_MAP","value":[{"type":"STRING","value":"records","dqpath":"/columns[1]/name","sqpath":"/columns[1]/name"},{"type":"MAP","value":{"comment":{"type":"STRING","value":"","dqpath":"/columns[1]/typeInfo/comment","sqpath":"/columns[1]/typeInfo/comment"},"type":{"type":"STRING","value":"BIGINT","dqpath":"/columns[1]/typeInfo/type","sqpath":"/columns[1]/typeInfo/type"},"extraInfo":{"type":"MAP","value":{},"dqpath":"/columns[1]/typeInfo/extraInfo","sqpath":"/columns[1]/typeInfo/extraInfo"}},"dqpath":"/columns[1]/typeInfo","sqpath":"/columns[1]/typeInfo"}],"dqpath":"/columns[1]","sqpath":"/columns[1]"}],"dqpath":"/columns","sqpath":"/columns"},{"type":"BOOLEAN","value":true,"dqpath":"/internal","sqpath":"/internal"},{"type":"STRING","value":"{\"type\":\"record\",\"name\":\"weather_all\",\"namespace\":\"default\",\"fields\":[{\"name\":\"area\",\"type\":[\"null\",\"string\"],\"default\":null},{\"name\":\"records\",\"type\":[\"null\",\"long\"],\"default\":null}]}","dqpath":"/avro_schema","sqpath":"/avro_schema"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::1","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::1::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']","errorTimestamp":1586686403018,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"0","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ivanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::2","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::2::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']","errorTimestamp":1586686403019,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"1","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Yuzhne","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::3","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::3::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']","errorTimestamp":1586686403020,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"2","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Teplodar","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::4","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::4::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']","errorTimestamp":1586686403021,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"3","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Atestovo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::5","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::5::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']","errorTimestamp":1586686403022,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"4","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Usatove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::6","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::6::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']","errorTimestamp":1586686403023,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"5","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kamyshevka Vtoraya","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::7","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::7::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']","errorTimestamp":1586686403023,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"6","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kulevcha","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::8","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::8::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']","errorTimestamp":1586686403024,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"7","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Fontanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::9","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::9::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586686403025,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"8","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sredniy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::10","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::10::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']","errorTimestamp":1586686403026,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"9","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Berezanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::11","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::11::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']","errorTimestamp":1586686403027,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"10","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Starokozache","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::12","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::12::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']","errorTimestamp":1586686403028,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"11","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Tayirove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::13","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::13::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']","errorTimestamp":1586686403028,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"12","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::14","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::14::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']","errorTimestamp":1586686403029,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"13","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Chervonoznamenka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::15","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::15::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']","errorTimestamp":1586686403030,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"14","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Palanca","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::16","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::16::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']","errorTimestamp":1586686403031,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"15","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rozdilna","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::17","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::17::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']","errorTimestamp":1586686403032,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"16","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kobleve","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::18","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::18::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']","errorTimestamp":1586686403033,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"17","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Dnestrovsc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::19","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::19::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']","errorTimestamp":1586686403034,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"18","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Illichivsk","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::20","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::20::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']","errorTimestamp":1586686403035,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"19","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::21","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::21::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586686403036,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"20","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krivaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::22","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::22::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']","errorTimestamp":1586686403037,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"21","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovsâke","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::23","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::23::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586686403038,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"22","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Malyy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::24","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::24::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']","errorTimestamp":1586686403040,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"23","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::25","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::25::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']","errorTimestamp":1586686403042,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"24","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilhorod-Dnistrovskyy","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::26","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::26::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']","errorTimestamp":1586686403043,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"25","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sukhyy Lyman","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::27","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::27::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']","errorTimestamp":1586686403044,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"26","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Oleksandrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::28","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::28::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']","errorTimestamp":1586686403044,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"27","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Lymanske","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::29","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::29::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']","errorTimestamp":1586686403045,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"28","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Zatoka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::30","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::30::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']","errorTimestamp":1586686403046,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"29","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Carahasani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::31","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::31::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']","errorTimestamp":1586686403047,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"30","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pervomaisc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::32","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::32::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']","errorTimestamp":1586686403049,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"31","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odesâka Oblastâ","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::33","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::33::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']","errorTimestamp":1586686403050,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"32","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilyayivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::34","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::34::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']","errorTimestamp":1586686403051,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"33","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"CÄplani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::35","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::35::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']","errorTimestamp":1586686403052,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"34","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odessa","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::36","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::36::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']","errorTimestamp":1586686403053,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"35","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Karolino-Buhaz","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::37","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::37::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']","errorTimestamp":1586686403056,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"36","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rybakivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::38","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::38::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']","errorTimestamp":1586686403057,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"37","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kryzhanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::39","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::39::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']","errorTimestamp":1586686403058,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"38","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Petrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::40","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::40::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']","errorTimestamp":1586686403059,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"39","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Verbany","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::41","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::41::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']","errorTimestamp":1586686403060,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"40","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ovidiopol","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::42","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::42::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']","errorTimestamp":1586686403060,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"41","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krasnosilka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::43","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::43::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586686403061,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"42","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kholodnaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::44","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::44::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']","errorTimestamp":1586686403067,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"43","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Crasnoe","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::45","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::45::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586686403068,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"44","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bolâshaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::46","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::46::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']","errorTimestamp":1586686403068,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"45","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Belyary","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::47","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::47::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']","errorTimestamp":1586686403069,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"46","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"OlÄneÅti","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::48","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::48::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']","errorTimestamp":1586686403069,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"47","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Shabo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::49","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::49::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']","errorTimestamp":1586686403070,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"48","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ochakiv","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::50","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::50::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']","errorTimestamp":1586686403070,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"49","mtime":"1586686016141","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-06-44/part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro","filename":"part-00000-22025841-93fb-4748-ac0e-7eb3c294e1c3-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sergeyevka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::1","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::1::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']","errorTimestamp":1586686452237,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"0","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ivanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::2","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::2::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']","errorTimestamp":1586686452238,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"1","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Yuzhne","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::3","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::3::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']","errorTimestamp":1586686452239,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"2","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Teplodar","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::4","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::4::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']","errorTimestamp":1586686452239,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"3","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Atestovo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::5","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::5::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']","errorTimestamp":1586686452240,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"4","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Usatove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::6","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::6::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']","errorTimestamp":1586686452241,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"5","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kamyshevka Vtoraya","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::7","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::7::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']","errorTimestamp":1586686452241,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"6","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kulevcha","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::8","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::8::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']","errorTimestamp":1586686452242,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"7","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Fontanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::9","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::9::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586686452242,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"8","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sredniy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::10","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::10::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']","errorTimestamp":1586686452243,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"9","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Berezanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::11","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::11::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']","errorTimestamp":1586686452243,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"10","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Starokozache","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::12","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::12::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']","errorTimestamp":1586686452243,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"11","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Tayirove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::13","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::13::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']","errorTimestamp":1586686452244,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"12","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::14","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::14::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']","errorTimestamp":1586686452244,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"13","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Chervonoznamenka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::15","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::15::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']","errorTimestamp":1586686452244,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"14","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Palanca","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::16","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::16::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']","errorTimestamp":1586686452245,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"15","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rozdilna","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::17","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::17::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']","errorTimestamp":1586686452245,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"16","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kobleve","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::18","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::18::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']","errorTimestamp":1586686452246,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"17","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Dnestrovsc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::19","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::19::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']","errorTimestamp":1586686452246,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"18","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Illichivsk","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::20","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::20::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']","errorTimestamp":1586686452247,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"19","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::21","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::21::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586686452247,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"20","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krivaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::22","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::22::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']","errorTimestamp":1586686452248,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"21","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovsâke","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::23","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::23::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586686452248,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"22","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Malyy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::24","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::24::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']","errorTimestamp":1586686452248,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"23","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::25","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::25::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']","errorTimestamp":1586686452249,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"24","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilhorod-Dnistrovskyy","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::26","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::26::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']","errorTimestamp":1586686452249,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"25","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sukhyy Lyman","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::27","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::27::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']","errorTimestamp":1586686452250,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"26","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Oleksandrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::28","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::28::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']","errorTimestamp":1586686452250,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"27","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Lymanske","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::29","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::29::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']","errorTimestamp":1586686452251,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"28","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Zatoka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::30","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::30::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']","errorTimestamp":1586686452251,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"29","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Carahasani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::31","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::31::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']","errorTimestamp":1586686452251,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"30","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pervomaisc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::32","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::32::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']","errorTimestamp":1586686452252,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"31","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odesâka Oblastâ","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::33","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::33::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']","errorTimestamp":1586686452252,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"32","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilyayivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::34","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::34::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']","errorTimestamp":1586686452253,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"33","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"CÄplani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::35","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::35::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']","errorTimestamp":1586686452253,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"34","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odessa","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::36","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::36::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']","errorTimestamp":1586686452253,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"35","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Karolino-Buhaz","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::37","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::37::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']","errorTimestamp":1586686452254,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"36","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rybakivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::38","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::38::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']","errorTimestamp":1586686452254,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"37","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kryzhanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::39","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::39::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']","errorTimestamp":1586686452255,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"38","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Petrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::40","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::40::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']","errorTimestamp":1586686452255,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"39","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Verbany","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::41","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::41::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']","errorTimestamp":1586686452256,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"40","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ovidiopol","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::42","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::42::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']","errorTimestamp":1586686452256,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"41","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krasnosilka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::43","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::43::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586686452257,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"42","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kholodnaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::44","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::44::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']","errorTimestamp":1586686452257,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"43","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Crasnoe","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::45","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::45::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586686452257,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"44","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bolâshaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::46","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::46::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']","errorTimestamp":1586686452258,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"45","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Belyary","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::47","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::47::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']","errorTimestamp":1586686452258,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"46","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"OlÄneÅti","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::48","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::48::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']","errorTimestamp":1586686452259,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"47","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Shabo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::49","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::49::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']","errorTimestamp":1586686452259,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"48","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ochakiv","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::50","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::50::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']","errorTimestamp":1586686452259,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"49","mtime":"1586686380479","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-12-48/part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro","filename":"part-00000-1f72cd06-c8e4-4eb2-8af5-53518943d6d8-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sergeyevka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}