¡{"header":{"stageCreator":"HiveMetadata_01","sourceId":"Table Metadata Recordb7faf6eb-3fc3-4e3a-a547-7ba270970e6d","stagesPath":"HiveMetadata_01","trackingId":"Table Metadata Recordb7faf6eb-3fc3-4e3a-a547-7ba270970e6d::HiveMetadata_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HadoopFS_01","errorStageLabel":"Hadoop FS 1","errorCode":"AVRO_GENERATOR_03","errorMessage":"AVRO_GENERATOR_03 - Record 'Table Metadata Recordb7faf6eb-3fc3-4e3a-a547-7ba270970e6d' is missing required header 'avroSchema'","errorTimestamp":1586685679155,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: AVRO_GENERATOR_03 - Record 'Table Metadata Recordb7faf6eb-3fc3-4e3a-a547-7ba270970e6d' is missing required header 'avroSchema'\n\tat com.streamsets.pipeline.stage.destination.hdfs.HdfsTarget$1.run(HdfsTarget.java:118)\n\tat com.streamsets.pipeline.stage.destination.hdfs.HdfsTarget$1.run(HdfsTarget.java:100)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1835)\n\tat com.streamsets.pipeline.stage.destination.hdfs.HdfsTarget.write(HdfsTarget.java:100)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"2","dqpath":"/version","sqpath":"/version"},{"type":"STRING","value":"TABLE","dqpath":"/type","sqpath":"/type"},{"type":"STRING","value":"default","dqpath":"/database","sqpath":"/database"},{"type":"STRING","value":"weather_all","dqpath":"/table","sqpath":"/table"},{"type":"STRING","value":"/user/hive/warehouse/weather_all","dqpath":"/location","sqpath":"/location"},{"type":"STRING","value":"PARQUET","dqpath":"/dataFormat","sqpath":"/dataFormat"},{"type":"LIST","value":[{"type":"LIST_MAP","value":[{"type":"STRING","value":"area","dqpath":"/columns[0]/name","sqpath":"/columns[0]/name"},{"type":"MAP","value":{"comment":{"type":"STRING","value":"","dqpath":"/columns[0]/typeInfo/comment","sqpath":"/columns[0]/typeInfo/comment"},"type":{"type":"STRING","value":"STRING","dqpath":"/columns[0]/typeInfo/type","sqpath":"/columns[0]/typeInfo/type"},"extraInfo":{"type":"MAP","value":{},"dqpath":"/columns[0]/typeInfo/extraInfo","sqpath":"/columns[0]/typeInfo/extraInfo"}},"dqpath":"/columns[0]/typeInfo","sqpath":"/columns[0]/typeInfo"}],"dqpath":"/columns[0]","sqpath":"/columns[0]"},{"type":"LIST_MAP","value":[{"type":"STRING","value":"records","dqpath":"/columns[1]/name","sqpath":"/columns[1]/name"},{"type":"MAP","value":{"comment":{"type":"STRING","value":"","dqpath":"/columns[1]/typeInfo/comment","sqpath":"/columns[1]/typeInfo/comment"},"type":{"type":"STRING","value":"BIGINT","dqpath":"/columns[1]/typeInfo/type","sqpath":"/columns[1]/typeInfo/type"},"extraInfo":{"type":"MAP","value":{},"dqpath":"/columns[1]/typeInfo/extraInfo","sqpath":"/columns[1]/typeInfo/extraInfo"}},"dqpath":"/columns[1]/typeInfo","sqpath":"/columns[1]/typeInfo"}],"dqpath":"/columns[1]","sqpath":"/columns[1]"}],"dqpath":"/columns","sqpath":"/columns"},{"type":"BOOLEAN","value":true,"dqpath":"/internal","sqpath":"/internal"},{"type":"STRING","value":"{\"type\":\"record\",\"name\":\"weather_all\",\"namespace\":\"default\",\"fields\":[{\"name\":\"area\",\"type\":[\"null\",\"string\"],\"default\":null},{\"name\":\"records\",\"type\":[\"null\",\"long\"],\"default\":null}]}","dqpath":"/avro_schema","sqpath":"/avro_schema"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::1","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::1::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685679166,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"0","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ivanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::2","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::2::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']","errorTimestamp":1586685679168,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"1","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Yuzhne","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::3","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::3::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']","errorTimestamp":1586685679172,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"2","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Teplodar","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::4","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::4::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']","errorTimestamp":1586685679173,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"3","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Atestovo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::5","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::5::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']","errorTimestamp":1586685679175,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"4","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Usatove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::6","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::6::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']","errorTimestamp":1586685679179,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"5","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kamyshevka Vtoraya","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::7","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::7::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']","errorTimestamp":1586685679180,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"6","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kulevcha","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::8","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::8::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']","errorTimestamp":1586685679182,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"7","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Fontanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::9","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::9::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586685679184,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"8","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sredniy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::10","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::10::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']","errorTimestamp":1586685679185,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"9","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Berezanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::11","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::11::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']","errorTimestamp":1586685679187,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"10","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Starokozache","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::12","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::12::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']","errorTimestamp":1586685679188,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"11","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Tayirove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::13","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::13::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']","errorTimestamp":1586685679189,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"12","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::14","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::14::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']","errorTimestamp":1586685679189,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"13","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Chervonoznamenka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::15","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::15::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']","errorTimestamp":1586685679190,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"14","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Palanca","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::16","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::16::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']","errorTimestamp":1586685679191,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"15","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rozdilna","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::17","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::17::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']","errorTimestamp":1586685679192,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"16","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kobleve","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::18","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::18::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']","errorTimestamp":1586685679193,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"17","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Dnestrovsc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::19","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::19::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']","errorTimestamp":1586685679195,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"18","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Illichivsk","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::20","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::20::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']","errorTimestamp":1586685679199,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"19","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::21","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::21::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685679200,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"20","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krivaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::22","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::22::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']","errorTimestamp":1586685679202,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"21","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovsâke","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::23","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::23::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586685679206,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"22","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Malyy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::24","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::24::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685679213,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"23","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::25","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::25::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']","errorTimestamp":1586685679217,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"24","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilhorod-Dnistrovskyy","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::26","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::26::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']","errorTimestamp":1586685679219,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"25","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sukhyy Lyman","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::27","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::27::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']","errorTimestamp":1586685679220,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"26","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Oleksandrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::28","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::28::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']","errorTimestamp":1586685679222,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"27","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Lymanske","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::29","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::29::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']","errorTimestamp":1586685679223,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"28","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Zatoka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::30","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::30::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']","errorTimestamp":1586685679226,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"29","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Carahasani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::31","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::31::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']","errorTimestamp":1586685679227,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"30","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pervomaisc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::32","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::32::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']","errorTimestamp":1586685679228,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"31","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odesâka Oblastâ","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::33","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::33::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']","errorTimestamp":1586685679229,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"32","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilyayivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::34","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::34::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']","errorTimestamp":1586685679230,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"33","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"CÄplani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::35","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::35::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']","errorTimestamp":1586685679231,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"34","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odessa","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::36","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::36::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']","errorTimestamp":1586685679233,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"35","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Karolino-Buhaz","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::37","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::37::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']","errorTimestamp":1586685679233,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"36","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rybakivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::38","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::38::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685679234,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"37","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kryzhanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::39","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::39::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']","errorTimestamp":1586685679236,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"38","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Petrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::40","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::40::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']","errorTimestamp":1586685679242,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"39","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Verbany","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::41","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::41::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']","errorTimestamp":1586685679244,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"40","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ovidiopol","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::42","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::42::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']","errorTimestamp":1586685679245,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"41","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krasnosilka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::43","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::43::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685679246,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"42","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kholodnaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::44","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::44::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']","errorTimestamp":1586685679247,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"43","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Crasnoe","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::45","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::45::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685679248,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"44","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bolâshaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::46","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::46::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']","errorTimestamp":1586685679249,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"45","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Belyary","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::47","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::47::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']","errorTimestamp":1586685679251,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"46","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"OlÄneÅti","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::48","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::48::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']","errorTimestamp":1586685679251,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"47","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Shabo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::49","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::49::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']","errorTimestamp":1586685679252,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"48","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ochakiv","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::50","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::50::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']","errorTimestamp":1586685679253,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"49","mtime":"1586685529351","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-09-58-38/part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro","filename":"part-00000-43fb9956-df94-4af4-b1dd-6314df3d6213-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sergeyevka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::1","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::1::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685727358,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"0","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ivanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::2","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::2::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']","errorTimestamp":1586685727359,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"1","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Yuzhne","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::3","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::3::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']","errorTimestamp":1586685727360,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"2","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Teplodar","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::4","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::4::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']","errorTimestamp":1586685727361,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"3","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Atestovo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::5","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::5::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']","errorTimestamp":1586685727362,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"4","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Usatove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::6","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::6::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']","errorTimestamp":1586685727364,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"5","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kamyshevka Vtoraya","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::7","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::7::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']","errorTimestamp":1586685727365,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"6","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kulevcha","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::8","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::8::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']","errorTimestamp":1586685727366,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"7","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Fontanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::9","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::9::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586685727367,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"8","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sredniy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::10","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::10::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']","errorTimestamp":1586685727368,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"9","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Berezanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::11","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::11::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']","errorTimestamp":1586685727369,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"10","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Starokozache","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::12","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::12::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']","errorTimestamp":1586685727370,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"11","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Tayirove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::13","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::13::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']","errorTimestamp":1586685727386,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"12","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::14","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::14::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']","errorTimestamp":1586685727388,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"13","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Chervonoznamenka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::15","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::15::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']","errorTimestamp":1586685727393,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"14","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Palanca","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::16","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::16::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']","errorTimestamp":1586685727395,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"15","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rozdilna","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::17","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::17::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']","errorTimestamp":1586685727395,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"16","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kobleve","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::18","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::18::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']","errorTimestamp":1586685727396,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"17","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Dnestrovsc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::19","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::19::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']","errorTimestamp":1586685727397,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"18","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Illichivsk","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::20","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::20::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']","errorTimestamp":1586685727397,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"19","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::21","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::21::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685727398,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"20","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krivaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::22","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::22::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']","errorTimestamp":1586685727399,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"21","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovsâke","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::23","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::23::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586685727400,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"22","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Malyy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::24","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::24::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685727400,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"23","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::25","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::25::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']","errorTimestamp":1586685727405,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"24","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilhorod-Dnistrovskyy","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::26","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::26::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']","errorTimestamp":1586685727406,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"25","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sukhyy Lyman","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::27","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::27::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']","errorTimestamp":1586685727406,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"26","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Oleksandrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::28","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::28::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']","errorTimestamp":1586685727409,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"27","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Lymanske","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::29","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::29::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']","errorTimestamp":1586685727410,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"28","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Zatoka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::30","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::30::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']","errorTimestamp":1586685727411,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"29","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Carahasani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::31","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::31::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']","errorTimestamp":1586685727412,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"30","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pervomaisc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::32","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::32::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']","errorTimestamp":1586685727414,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"31","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odesâka Oblastâ","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::33","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::33::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']","errorTimestamp":1586685727421,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"32","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilyayivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::34","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::34::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']","errorTimestamp":1586685727423,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"33","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"CÄplani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::35","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::35::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']","errorTimestamp":1586685727425,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"34","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odessa","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::36","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::36::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']","errorTimestamp":1586685727426,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"35","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Karolino-Buhaz","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::37","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::37::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']","errorTimestamp":1586685727427,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"36","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rybakivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::38","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::38::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685727429,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"37","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kryzhanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::39","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::39::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']","errorTimestamp":1586685727430,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"38","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Petrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::40","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::40::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']","errorTimestamp":1586685727432,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"39","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Verbany","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::41","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::41::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']","errorTimestamp":1586685727435,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"40","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ovidiopol","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::42","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::42::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']","errorTimestamp":1586685727436,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"41","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krasnosilka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::43","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::43::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685727437,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"42","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kholodnaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::44","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::44::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']","errorTimestamp":1586685727439,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"43","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Crasnoe","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::45","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::45::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685727439,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"44","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bolâshaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::46","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::46::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']","errorTimestamp":1586685727440,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"45","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Belyary","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::47","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::47::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']","errorTimestamp":1586685727440,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"46","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"OlÄneÅti","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::48","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::48::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']","errorTimestamp":1586685727441,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"47","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Shabo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::49","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::49::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']","errorTimestamp":1586685727442,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"48","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ochakiv","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::50","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::50::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']","errorTimestamp":1586685727442,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"49","mtime":"1586685650959","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-00-39/part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro","filename":"part-00000-61d9e1ba-b728-4a67-9eb1-971017b3391b-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sergeyevka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::1","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::1::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685825555,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::1]' data='Field[MAP:{area=Field[STRING:Ivanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"0","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ivanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::2","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::2::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']","errorTimestamp":1586685825556,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::2]' data='Field[MAP:{area=Field[STRING:Yuzhne], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"1","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Yuzhne","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::3","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::3::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']","errorTimestamp":1586685825557,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::3]' data='Field[MAP:{area=Field[STRING:Teplodar], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"2","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Teplodar","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::4","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::4::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']","errorTimestamp":1586685825558,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::4]' data='Field[MAP:{area=Field[STRING:Atestovo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"3","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Atestovo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::5","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::5::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']","errorTimestamp":1586685825559,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::5]' data='Field[MAP:{area=Field[STRING:Usatove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"4","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Usatove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::6","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::6::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']","errorTimestamp":1586685825559,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::6]' data='Field[MAP:{area=Field[STRING:Kamyshevka Vtoraya], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"5","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kamyshevka Vtoraya","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::7","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::7::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']","errorTimestamp":1586685825561,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::7]' data='Field[MAP:{area=Field[STRING:Kulevcha], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"6","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kulevcha","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::8","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::8::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']","errorTimestamp":1586685825561,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::8]' data='Field[MAP:{area=Field[STRING:Fontanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"7","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Fontanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::9","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::9::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586685825563,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::9]' data='Field[MAP:{area=Field[STRING:Sredniy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"8","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sredniy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::10","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::10::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']","errorTimestamp":1586685825564,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::10]' data='Field[MAP:{area=Field[STRING:Berezanka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"9","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Berezanka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::11","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::11::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']","errorTimestamp":1586685825565,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::11]' data='Field[MAP:{area=Field[STRING:Starokozache], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"10","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Starokozache","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::12","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::12::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']","errorTimestamp":1586685825566,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::12]' data='Field[MAP:{area=Field[STRING:Tayirove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"11","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Tayirove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::13","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::13::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']","errorTimestamp":1586685825567,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::13]' data='Field[MAP:{area=Field[STRING:Pokrovka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"12","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::14","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::14::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']","errorTimestamp":1586685825568,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::14]' data='Field[MAP:{area=Field[STRING:Chervonoznamenka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"13","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Chervonoznamenka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::15","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::15::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']","errorTimestamp":1586685825570,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::15]' data='Field[MAP:{area=Field[STRING:Palanca], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"14","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Palanca","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::16","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::16::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']","errorTimestamp":1586685825571,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::16]' data='Field[MAP:{area=Field[STRING:Rozdilna], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"15","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rozdilna","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::17","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::17::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']","errorTimestamp":1586685825572,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::17]' data='Field[MAP:{area=Field[STRING:Kobleve], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"16","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kobleve","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::18","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::18::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']","errorTimestamp":1586685825572,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::18]' data='Field[MAP:{area=Field[STRING:Dnestrovsc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"17","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Dnestrovsc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::19","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::19::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']","errorTimestamp":1586685825574,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::19]' data='Field[MAP:{area=Field[STRING:Illichivsk], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"18","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Illichivsk","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::20","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::20::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']","errorTimestamp":1586685825574,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::20]' data='Field[MAP:{area=Field[STRING:Stepove], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"19","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepove","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::21","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::21::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685825576,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::21]' data='Field[MAP:{area=Field[STRING:Krivaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"20","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krivaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::22","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::22::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']","errorTimestamp":1586685825577,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::22]' data='Field[MAP:{area=Field[STRING:Pokrovsâke], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"21","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pokrovsâke","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::23","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::23::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']","errorTimestamp":1586685825578,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::23]' data='Field[MAP:{area=Field[STRING:Malyy Fontan], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"22","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Malyy Fontan","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::24","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::24::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685825580,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::24]' data='Field[MAP:{area=Field[STRING:Stepanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"23","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Stepanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::25","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::25::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']","errorTimestamp":1586685825581,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::25]' data='Field[MAP:{area=Field[STRING:Bilhorod-Dnistrovskyy], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"24","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilhorod-Dnistrovskyy","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::26","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::26::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']","errorTimestamp":1586685825582,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::26]' data='Field[MAP:{area=Field[STRING:Sukhyy Lyman], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"25","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sukhyy Lyman","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::27","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::27::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']","errorTimestamp":1586685825583,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::27]' data='Field[MAP:{area=Field[STRING:Oleksandrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"26","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Oleksandrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::28","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::28::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']","errorTimestamp":1586685825584,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::28]' data='Field[MAP:{area=Field[STRING:Lymanske], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"27","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Lymanske","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::29","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::29::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']","errorTimestamp":1586685825586,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::29]' data='Field[MAP:{area=Field[STRING:Zatoka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"28","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Zatoka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::30","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::30::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']","errorTimestamp":1586685825587,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::30]' data='Field[MAP:{area=Field[STRING:Carahasani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"29","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Carahasani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::31","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::31::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']","errorTimestamp":1586685825589,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::31]' data='Field[MAP:{area=Field[STRING:Pervomaisc], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"30","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Pervomaisc","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::32","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::32::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']","errorTimestamp":1586685825590,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::32]' data='Field[MAP:{area=Field[STRING:Odesâka Oblastâ], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"31","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odesâka Oblastâ","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::33","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::33::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']","errorTimestamp":1586685825591,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::33]' data='Field[MAP:{area=Field[STRING:Bilyayivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"32","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bilyayivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::34","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::34::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']","errorTimestamp":1586685825591,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::34]' data='Field[MAP:{area=Field[STRING:CÄplani], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"33","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"CÄplani","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::35","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::35::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']","errorTimestamp":1586685825592,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::35]' data='Field[MAP:{area=Field[STRING:Odessa], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"34","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Odessa","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::36","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::36::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']","errorTimestamp":1586685825593,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::36]' data='Field[MAP:{area=Field[STRING:Karolino-Buhaz], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"35","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Karolino-Buhaz","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::37","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::37::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']","errorTimestamp":1586685825593,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::37]' data='Field[MAP:{area=Field[STRING:Rybakivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"36","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Rybakivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::38","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::38::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']","errorTimestamp":1586685825594,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::38]' data='Field[MAP:{area=Field[STRING:Kryzhanivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"37","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kryzhanivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::39","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::39::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']","errorTimestamp":1586685825595,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::39]' data='Field[MAP:{area=Field[STRING:Petrivka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"38","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Petrivka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::40","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::40::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']","errorTimestamp":1586685825595,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::40]' data='Field[MAP:{area=Field[STRING:Verbany], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"39","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Verbany","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::41","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::41::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']","errorTimestamp":1586685825596,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::41]' data='Field[MAP:{area=Field[STRING:Ovidiopol], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"40","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ovidiopol","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::42","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::42::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']","errorTimestamp":1586685825597,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::42]' data='Field[MAP:{area=Field[STRING:Krasnosilka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"41","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Krasnosilka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::43","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::43::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685825600,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::43]' data='Field[MAP:{area=Field[STRING:Kholodnaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"42","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Kholodnaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::44","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::44::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']","errorTimestamp":1586685825601,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::44]' data='Field[MAP:{area=Field[STRING:Crasnoe], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"43","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Crasnoe","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::45","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::45::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']","errorTimestamp":1586685825603,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::45]' data='Field[MAP:{area=Field[STRING:Bolâshaya Balka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"44","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Bolâshaya Balka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::46","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::46::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']","errorTimestamp":1586685825604,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::46]' data='Field[MAP:{area=Field[STRING:Belyary], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"45","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Belyary","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::47","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::47::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']","errorTimestamp":1586685825605,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::47]' data='Field[MAP:{area=Field[STRING:OlÄneÅti], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"46","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"OlÄneÅti","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::48","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::48::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']","errorTimestamp":1586685825605,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::48]' data='Field[MAP:{area=Field[STRING:Shabo], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"47","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Shabo","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::49","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::49::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']","errorTimestamp":1586685825606,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::49]' data='Field[MAP:{area=Field[STRING:Ochakiv], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"48","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Ochakiv","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}
 {"header":{"stageCreator":"HadoopFSStandalone_01","sourceId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::50","stagesPath":"HadoopFSStandalone_01","trackingId":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::50::HadoopFSStandalone_01","previousTrackingId":null,"raw":null,"rawMimeType":null,"errorDataCollectorId":"73c64506-6fa2-11ea-80c6-d162cc9dd014","errorPipelineName":"ToHivestada33311f-29ff-435f-8582-dc491ad1cfc9","errorStage":"HiveMetastore_01","errorStageLabel":"Hive Metastore 1","errorCode":"HIVE_17","errorMessage":"HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']","errorTimestamp":1586685825607,"errorStackTrace":"com.streamsets.pipeline.api.base.OnRecordErrorException: HIVE_17 - Information type missing or invalid in the metadata record: Record[headers='HeaderImpl[part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro::50]' data='Field[MAP:{area=Field[STRING:Sergeyevka], records=Field[LONG:50]}]']\n\tat com.streamsets.pipeline.stage.destination.hive.HiveMetastoreTarget.write(HiveMetastoreTarget.java:202)\n\tat com.streamsets.pipeline.api.base.configurablestage.DTarget.write(DTarget.java:34)\n\tat com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:303)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:244)\n\tat com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:311)\n\tat com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:220)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:854)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.lambda$executeRunner$3(ProductionPipelineRunner.java:898)\n\tat com.streamsets.datacollector.runner.PipeRunner.acceptConsumer(PipeRunner.java:221)\n\tat com.streamsets.datacollector.runner.PipeRunner.executeBatch(PipeRunner.java:142)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.executeRunner(ProductionPipelineRunner.java:897)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runSourceLessBatch(ProductionPipelineRunner.java:875)\n\tat com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processBatch(ProductionPipelineRunner.java:505)\n\tat com.streamsets.datacollector.runner.StageRuntime$3.run(StageRuntime.java:383)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat com.streamsets.datacollector.runner.StageRuntime.processBatch(StageRuntime.java:379)\n\tat com.streamsets.datacollector.runner.StageContext.processBatch(StageContext.java:290)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.produce(SpoolDirRunnable.java:327)\n\tat com.streamsets.pipeline.lib.dirspooler.SpoolDirRunnable.run(SpoolDirRunnable.java:148)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226)\n\tat com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222)\n\tat com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeRunnable.run(SafeScheduledExecutorService.java:188)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorJobId":null,"values":{"avro.union.typeIndex./area":"0","offset":"49","mtime":"1586685771672","avroSchema":"{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"area\",\"type\":[\"string\",\"null\"]},{\"name\":\"records\",\"type\":\"long\"}]}","baseDir":"/out/bronze/weather2hive/*","file":"/out/bronze/weather2hive/2020-04-12-10-02-40/part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro","filename":"part-00000-706885b2-a424-4cfb-9f36-d9a15e5a570a-c000.avro"}},"value":{"type":"LIST_MAP","value":[{"type":"STRING","value":"Sergeyevka","dqpath":"/area","sqpath":"/area"},{"type":"LONG","value":"50","dqpath":"/records","sqpath":"/records"}],"dqpath":"","sqpath":""}}