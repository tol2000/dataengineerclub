= Проект выпускника курсов OTUS Data engineering Клюсы А.Ю.

== Current

- При записи таблица блокируется...
- Все-таки select count(*) не выполняется +
  Поэтому пока нельзя выполнить загрузку
  данных в серебряный слой
- Организовываем якорную модель DWH серебряного слоя
  (погода или все-таки реддит)
  при помощи anchormodeling.com
- Приступать к поднятию контейнера с вертикой
  (см. инструкцию к домашке по моделям DWH)
  или все-таки грузить в импалу,
  чтобы не выходить за пределы клаудеры
  С вертикой работает anchormodeling.com
  С импалой не знаю, да и нас с ней не оч знакомили,
  а по вертике у нас есть много скриптов в домашке.
- Загрузка в серебряный слой скорее всего будет
  батчами spark+scala
  пример можно поискать в домашке
  по обучению модели, но там на питоне,
  можно на скале, за этим к домашкам по винному
  магазину и Бостону
- Кстати, в вертику можно попытаться загрузить
  опять же со стримсета
- Спарк+скала можно все-таки применить, т.к. в
  клаудере оно уже есть, для каких-то мощных
  обсчитываний.
- Опять же, спарк можно вызывать из стримсета
- Если и мониторинг прикрутить в стримсете, то
  это будет неплохая экосистема внутри.

После консультации

Основное, что подключить:

- спарк + скала + датафрейм/датасет апи серебряного слоя,
  который, скажем, выбирает что-то из всей инфы и пишет в тот же хайв или вертику

- https://stackoverflow.com/questions/38521048/hdfs-as-volume-in-cloudera-quickstart-docker




== Постановка задачи

=== Хранилище

Типа Datalake

=== Мониторинг

Функции мониторинга также может взять на себя streamsets

== Примечания

=== Установка и настройка

NOTE: To avoid of oversizing git repo +
streamsets stage libraries maps to +
*~/ssdc-stagelibs* (must have 777 attrs)

* docker-compose up

==== streamsets

https://hub.docker.com/r/streamsets/datacollector/

* location locahost: 18630
* credentials
** admin/admin

==== cloudera-quickstart

https://github.com/emirkorkmaz/cloudera-quickstart-docker-compose

* location: localhost
** 8020   # HDFS 
** 8022   # SSH
** 7180   # Cloudera Manager
** 8888   # Hue
** 11000  # Oozie
** 50070  # HDFS Rest Namenode
** 50075  # HDFS Rest Datanode
** 2181   # Zookeeper
** 8088   # YARN Resource Manager
** 19888  # MapReduce Job History
** 50030  # MapReduce Job Tracker
** 8983   # Solr
** 16000  # Sqoop Metastore
** 8042   # YARN Node Manager
** 60010  # HBase Master
** 60030  # HBase Region
** 9090   # HBase Thrift
** 8080   # HBase Rest
** 7077   # Spark Master
** 10000  # Hive jdbc
** 10002  # Hive web interface

* credentials
** claudera manager: admin/admin
** hue: claudera/claudera
* versions
** CDH 5.7.0
** Hadoop 2.6.0
** Hive 1.1.0

===== Cloudera manager (optional)

[source, bash]
----
docker ps -a
docker attach container-id
/home/cloudera/cloudera-manager --express --force
----

* connect to localhost:7180
* restart all services in cluster

=== Загрузка информации из публичного источника (rss, rest, иное)

Возможно, использовать стримсет и его коннекторы

https://rapidapi.com/collection/top-weather-apis?utm_source=google&utm_medium=cpc&utm_campaign=1674315309_64978333346&utm_term=weather%20api%20free_b&utm_content=&gclid=Cj0KCQjwpfHzBRCiARIsAHHzyZoekUFE3eg8G3S297tNcOwMg8UkDKHFF32FnGOIW3XMhEMc6_nv7BkaAvziEALw_wcB

==== Источник openweathermap.org

https://openweathermap.org/

api.openweathermap.org/data/2.5/weather?q={city name},{state},{country code}&appid={your api key}

https://api.openweathermap.org/data/2.5/weather?q=Odessa,ua&appid=d12dd3e0376f206595b3a0660911c2dc


* Выбираем погоду в 50 пунктах вокруг Одессы и находим мин/макс температуру +
https://api.openweathermap.org/data/2.5/find?lat=46.4859841&lon=30.7249136&cnt=50&appid=d12dd3e0376f206595b3a0660911c2dc


=== Инициализация

==== Claudera

===== Scripts

In hue or other sql client

[source, sql]
----
create database if not exists bronze;

----

=== Список используемой литературы

https://github.com/streamsets/tutorials/blob/master/tutorial-hivedrift/readme.md

=== Other

Здравствуйте!

Вот тут более подробные наброски для моего проекта.
https://github.com/tol2000/dataengineerclub/blob/master/project/%D0%A1%D1%85%D0%B5%D0%BC%D0%B0%20%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%B0.svg

Из всего этого уже работает загрузка погоды через rest api в стримсетс.
Все планирую в докер-контейнерах, подобно тем, что мы использовали в процессе обучения:
streamsets, cloudera-quickstart, vertica-quickstart

Функции мониторинга и планировщика, думаю, возьмет на себя стримсетс.
Конечно, было бы здорово подключить и apache airflow, но, боюсь, не успею.
Попробую реализовать задуманное хотя бы в формате какого-то одного бизнес-кейса.

Как считаете, достойно для проекта и реально для теоретического применения хоть где-то? )