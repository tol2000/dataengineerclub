= Проект выпускника курсов OTUS Data engineering Клюсы А.Ю.

== Доделать

В запросе есть поля rain, snow
им генерит спарк тип map, который
не поддерживается metadata.
в общем, или исключить такие поля
или преобразовать тип...
вообще, добавление полей кроме name, dt
вызывает какие-то судороги либо у спарка либо у streamsets metadata
или проверить или оставить как есть, выбирая те, что работают )

может, поставить в стримсетс какой-то field type converter
(там тип map какой-то генерится)

проверить также, в точке ли дело в именах полей или в другом


Также, возможно, доделать DWH серебряного слоя,
и сделать одну витринку...

Возможно, вместо якорной модели выбрать
другую модель (тех чуваком, что вначале ее создавали).

Возможно, так удастся закончить проект вовремя :)

Ну и... метадата + метастор у стримсетс
отлично реализуют модель dwh, когда любой новый атрибут
просто добавляется в общую таблицу...

Поскольку я выполняю flatten columns
при помощи того же стримсетс, то любые атрибуты и
субатрибуты - это просто новые стоблцы.
Хранилище получается денормализованным.
Скажем, если добавляется атрибут координаты, а
у него есть субатрибуты широта и долгота,
то в таблице это будут два дополнительных
поля координаты.широта и координаты.долгота.

То есть, реализуем модель не якорную, а
противоположную.

Якорную модель я уже изучил в ДЗ по моделированию DWH.

== Current

- DWH в hive.
  Главная фишка тогда в том, что можно один и тот же
  паркет или орк, и движок юзать, например, импала,
  типа это MPP, или hive, типа это эээ... просто DWH :)
  каждый движок работает с одним и тем же файлом, но
  по-разному, в этом и прикол :)
  https://habr.com/ru/post/486124/
- Загрузка в серебряный слой скорее всего будет
  батчами spark+scala
  пример можно поискать в домашке
  по обучению модели, но там на питоне,
  можно на скале, за этим к домашкам по винному
  магазину и Бостону
- Кстати, в вертику можно попытаться загрузить
  опять же со стримсета
- Спарк+скала можно все-таки применить, т.к. в
  клаудере оно уже есть, для каких-то мощных
  обсчитываний.
- Опять же, спарк можно вызывать из стримсета
- Если и мониторинг прикрутить в стримсете, то
  это будет неплохая экосистема внутри.

== Постановка задачи

=== Хранилище

Типа Datalake

==== Бронзовый слой

===== Таблица сырых данных tsource

* Кладется в HDFS в виде json-файлов +
  размер задается, при его превышении создается новый файл +
  таким образом можно создавать файлы оптимального для HDFS размера

* Размер пока в записях, в МБ не работет. +
  Вернее, нужно проверить, задать, скажем, 1М или меньше...

==== Spark

Очень хотел запустить на quickstart.cloudera на yarn, но
там требуется скомпилировать на старом спарке 1.6 и яве 1.7
(на них работает клаудеровский контейнер).

Если на спарк 1.6 я еще перевел, то установить яву 1.7 на свою ОС
мне не удалось по причине того, что нужно много даунгрейдить.

Потратил много времени, безуспешно пытаясь это все побороть.

В итоге решил запускать спарк локально в самом контейнере стримсета
(там я пробросил каталог со спарком 2).

=== Мониторинг

Функции мониторинга также может взять на себя streamsets

== Примечания

=== Установка и настройка

NOTE: To avoid of oversizing git repo +
streamsets stage libraries maps to +
*~/ssdc-stagelibs* (must have 777 attrs)

* docker-compose up

==== streamsets

===== Описание подключения необходимых стейджей в streamsets

В домашнем каталоге должен лежать каталог `sdc-stagelibs`
с необходимым содержимым (доинсталлированные библиотеки).
Содержимое прилагается отдельно или просто после запуска доставляются
необходимые стейджы стримсетс.

Так сделано потому, чтобы не перегружать репозиторий гита
лишними 500+ мегабайт

Потом он в docker-compose yaml мапится в соотв. каталог докера.

https://hub.docker.com/r/streamsets/datacollector/

* location locahost: 18630
* credentials
** admin/admin

==== cloudera-quickstart

https://github.com/emirkorkmaz/cloudera-quickstart-docker-compose

* location: localhost
** 8020   # HDFS 
** 8022   # SSH
** 7180   # Cloudera Manager
** 8888   # Hue
** 11000  # Oozie
** 50070  # HDFS Rest Namenode
** 50075  # HDFS Rest Datanode
** 2181   # Zookeeper
** 8088   # YARN Resource Manager
** 19888  # MapReduce Job History
** 50030  # MapReduce Job Tracker
** 8983   # Solr
** 16000  # Sqoop Metastore
** 8042   # YARN Node Manager
** 60010  # HBase Master
** 60030  # HBase Region
** 9090   # HBase Thrift
** 8080   # HBase Rest
** 7077   # Spark Master
** 10000  # Hive jdbc
** 10002  # Hive web interface

* credentials
** claudera manager: admin/admin
** hue: claudera/claudera
* versions
** CDH 5.7.0
** Hadoop 2.6.0
** Hive 1.1.0

===== Cloudera manager (optional)

[source, bash]
----
docker ps -a
docker attach container-id
/home/cloudera/cloudera-manager --express --force
----

* connect to localhost:7180
* restart all services in cluster

=== Загрузка информации из публичного источника (rss, rest, иное)

Используем стримсет и его коннекторы

https://rapidapi.com/collection/top-weather-apis?utm_source=google&utm_medium=cpc&utm_campaign=1674315309_64978333346&utm_term=weather%20api%20free_b&utm_content=&gclid=Cj0KCQjwpfHzBRCiARIsAHHzyZoekUFE3eg8G3S297tNcOwMg8UkDKHFF32FnGOIW3XMhEMc6_nv7BkaAvziEALw_wcB

==== Источник openweathermap.org

https://openweathermap.org/

api.openweathermap.org/data/2.5/weather?q={city name},{state},{country code}&appid={your api key}

https://api.openweathermap.org/data/2.5/weather?q=Odessa,ua&appid=d12dd3e0376f206595b3a0660911c2dc


* Выбираем погоду в 50 пунктах вокруг Одессы и находим мин/макс температуру +
https://api.openweathermap.org/data/2.5/find?lat=46.4859841&lon=30.7249136&cnt=50&appid=d12dd3e0376f206595b3a0660911c2dc


=== Запуск

==== Streamsets

Check for dir: `~/sdc-stagelibs`

=== Демонстрация

==== Hive

Поскольку в таблицу происходит непрерывное добавление,
запросы вроде select count(*) вызывают ошибку, т.к. hive пытается
считать все датафайлы, в том числе и те, что еще не дописались

А вот запрос, который работает явно с партициями, выполняется. +
Видимо, Hive в этом случае обрабатывает только закрытые партиции.
Пример рабочего запроса ниже.

[source, sql]
----
select dt,count(*) from weather_all group by dt;
select count(*) from weather_all where dt<='2020-04-13-00-04';
----

=== Завершение

==== Streamsets

* Stop pipeline BronzeLayerStream

==== Claudera

====== Hive

[source, sql]
----
----

====== docker bash

[source, bash]
----
----
