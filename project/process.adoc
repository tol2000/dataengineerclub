= Проект выпускника курсов OTUS Data engineering Клюсы А.Ю.

== Current

- При записи таблица блокируется...
- Все-таки select count(*) не выполняется +
  Поэтому пока нельзя выполнить загрузку
  данных в серебряный слой
- Организовываем якорную модель DWH серебряного слоя
  (погода или все-таки реддит)
  при помощи anchormodeling.com
- Приступать к поднятию контейнера с вертикой
  (см. инструкцию к домашке по моделям DWH)
  или все-таки грузить в импалу,
  чтобы не выходить за пределы клаудеры
  С вертикой работает anchormodeling.com
  С импалой не знаю, да и нас с ней не оч знакомили,
  а по вертике у нас есть много скриптов в домашке.
  Кстати, вертика умеет читать из того же паркета
  при помощи механизма внешней таблицы,
  так можно читать прямо из хдфс клаудеровской,
  а писаться туда будет спарком или стримсетсом.
  Но тогда теряется много преимуществ вертики, если
  таблица не в ее епархии располагается, только движок...
  Все-таки импала?..
  Возможно, оставлю тоже в hive.
  Главная фишка тогда в том, что можно один и тот же
  паркет или орк, и движок юзать, например, импала,
  типа это MPP, или hive, типа это эээ... просто DWH :)
  каждый движок работает с одним и тем же файлом, но
  по-разному, в этом и прикол :)
  https://habr.com/ru/post/486124/
- Загрузка в серебряный слой скорее всего будет
  батчами spark+scala
  пример можно поискать в домашке
  по обучению модели, но там на питоне,
  можно на скале, за этим к домашкам по винному
  магазину и Бостону
- Кстати, в вертику можно попытаться загрузить
  опять же со стримсета
- Спарк+скала можно все-таки применить, т.к. в
  клаудере оно уже есть, для каких-то мощных
  обсчитываний.
- Опять же, спарк можно вызывать из стримсета
- Если и мониторинг прикрутить в стримсете, то
  это будет неплохая экосистема внутри.

== После консультации

Основное, что подключить:

- Сделать проброс хдфс (см. описание квикстарта клаудеры) +
  пробросить в хоум, по инструкции +
  хотя, если хдфс выйдет небольшим, то, может, прямо в гитхаб... )

- После всего этого как-то добавить эти файлы +
  (и стримсета и хдфс и, может, еще что-то будет)
  в гит с инструкцией развернуть их в хоуме до старта контейнера +
  желательно когда проект будет завершен, чтобы там уже все было

- спарк + скала + датафрейм/датасет апи серебряного слоя,
  который, скажем, выбирает что-то из всей инфы и пишет в тот же хайв или вертику

- https://stackoverflow.com/questions/38521048/hdfs-as-volume-in-cloudera-quickstart-docker




== Постановка задачи

=== Хранилище

Типа Datalake

==== Бронзовый слой

===== Таблица сырых данных weather

* Создана с партицированием вплоть до часа. +
  Такое мелкое партицирование сделано в учебных целях.
* Для стриминга в streamsets требуется bucketing, создал 2 бакета на основе поля hour,
  в реале там, конечно же, будут перекосы.

=== Мониторинг

Функции мониторинга также может взять на себя streamsets

== Примечания

=== Установка и настройка

NOTE: To avoid of oversizing git repo +
streamsets stage libraries maps to +
*~/ssdc-stagelibs* (must have 777 attrs)

* docker-compose up

==== streamsets

===== Описание подключения необходимых стейджей в streamsets

В домашнем каталоге должен лежать каталог `sdc-stagelibs`
с необходимым содержимым (доинсталлированные библиотеки).
Содержимое прилагается отдельно.

Потом он в docker-compose yaml мапится в соотв. каталог докера.

https://hub.docker.com/r/streamsets/datacollector/

* location locahost: 18630
* credentials
** admin/admin

==== cloudera-quickstart

https://github.com/emirkorkmaz/cloudera-quickstart-docker-compose

* location: localhost
** 8020   # HDFS 
** 8022   # SSH
** 7180   # Cloudera Manager
** 8888   # Hue
** 11000  # Oozie
** 50070  # HDFS Rest Namenode
** 50075  # HDFS Rest Datanode
** 2181   # Zookeeper
** 8088   # YARN Resource Manager
** 19888  # MapReduce Job History
** 50030  # MapReduce Job Tracker
** 8983   # Solr
** 16000  # Sqoop Metastore
** 8042   # YARN Node Manager
** 60010  # HBase Master
** 60030  # HBase Region
** 9090   # HBase Thrift
** 8080   # HBase Rest
** 7077   # Spark Master
** 10000  # Hive jdbc
** 10002  # Hive web interface

* credentials
** claudera manager: admin/admin
** hue: claudera/claudera
* versions
** CDH 5.7.0
** Hadoop 2.6.0
** Hive 1.1.0

===== Cloudera manager (optional)

[source, bash]
----
docker ps -a
docker attach container-id
/home/cloudera/cloudera-manager --express --force
----

* connect to localhost:7180
* restart all services in cluster

=== Загрузка информации из публичного источника (rss, rest, иное)

Возможно, использовать стримсет и его коннекторы

https://rapidapi.com/collection/top-weather-apis?utm_source=google&utm_medium=cpc&utm_campaign=1674315309_64978333346&utm_term=weather%20api%20free_b&utm_content=&gclid=Cj0KCQjwpfHzBRCiARIsAHHzyZoekUFE3eg8G3S297tNcOwMg8UkDKHFF32FnGOIW3XMhEMc6_nv7BkaAvziEALw_wcB

==== Источник openweathermap.org

https://openweathermap.org/

api.openweathermap.org/data/2.5/weather?q={city name},{state},{country code}&appid={your api key}

https://api.openweathermap.org/data/2.5/weather?q=Odessa,ua&appid=d12dd3e0376f206595b3a0660911c2dc


* Выбираем погоду в 50 пунктах вокруг Одессы и находим мин/макс температуру +
https://api.openweathermap.org/data/2.5/find?lat=46.4859841&lon=30.7249136&cnt=50&appid=d12dd3e0376f206595b3a0660911c2dc


=== Инициализация

==== Claudera

===== Scripts

====== Hive

[source, sql]
----
create database if not exists
  bronze
  comment 'bronze layer database'
;

use bronze;

drop table weather;
create external table if not exists
  weather (
    forbucketing int,
    text string
  )
  comment 'raw data from source weather'
  partitioned by (year int)
  clustered by (forbucketing) into 2 buckets
;
----

    time timestamp,

====== Impala

[source, sql]
----
----

====== Before shutdown - export

insert overwrite local directory '/media/shared_from_local/bronze/weather' select * from bronze.weather;

=== Список используемой литературы

https://github.com/streamsets/tutorials/blob/master/tutorial-hivedrift/readme.md

