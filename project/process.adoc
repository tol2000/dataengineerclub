= Проект выпускника курсов OTUS Data engineering Клюсы А.Ю.

== Тема

Создание архитектуры по сбору, хранению и отслеживанию данных о погоде
из открытого источника http://openweathermap.org

== Постановка задачи

=== Стоимость

Поскольку проект предназначен для использования в небольших
организациях или в личных целях, либо в каких-то небольших
научных исследованиях с малым бюджетом, я предполагал
применение только свободно распространяемых решений.

Таким образом, стоимость ПО для данного проекта нулевая.

=== Используемое программное обеспечение

* Streamsets (в учебном docker-контейнере)
* Cloudera CDH 5.7 (в учебном docker-контейнере)
* Spark 2.4.4
* Scala 2.11.12
* OS Linux Fedora 31 workstation

==== Вспомогательное ПО

* VS code
* Intelligent IDE Community edition with scala plugin
* Сборщик sbt
* PlantUML: построение UML диаграмм as a code
* Git + github
* Docker
* Oracle Virtualbox

=== Источник данных

Информация с сайта источника http://openweathermap.org
(при помощи rest api)

=== Хранилище

Типа Datalake

=== Витрины и бизнес-кейсы

Отслеживание погодных изменений по Одессе

=== Схема проекта

image:

== Реализация

=== Источник данных

* Проведена регистрация на сайте http://openweathermap.org
* Получен ключ для использования API в приложениях

=== Хранилище

В качестве хранилища данных использовал клаудеровские HDFS и Hive.
Остановился на этом, т.к. на большее не позволяло время, ресурсы
компьютера, да и проект декларируется как легкий и бюджетный.

Все это в предустановленном учебном контейнере quickstart.cloudera.

==== Бронзовый слой

Находится в HDFS в виде сырых json-файлов, поступивших от openweathermap.

Размер одного файла около 1МиБ (в учебных целях, в реальности больше).

Эти файлы не удаляются, в чем и есть предназначение бронзового слоя,
в любой момент из них можно повторно загрузить необходимую информацию.

==== Серебряный слой

Организован по принципу Ральфа Кимбалла.

Проект нацелен на бюджетность и его реализация была сильно ограничена во времени.
Поэтому я пришел к выводу, что нужно делать все максимально просто, эффективно и
для "здесь и сейчас".

Метод организации хранилища по принципу "что сейчас нужно для клиента, то и реализуем"
здесь, как мне кажется, подходит.

Для каждого бизнес-кейса в хранилище реализуется своя отдельная таблица и в спарковой,
джобе, которая перекачивает данные из необработанных в хранилище, для каждого
такого кейса предусмотрен отдельный блок кода и отдельный запрос.

===== Примечания

====== Что задумывалось

Задумывалась якорная модель хранилища и ее частичная реализация.

Мне вообще нравится якорная модель. Она мощная и гибкая.
Правда, громоздкая и сложно реализуемая.

Однако, из-за нехватки времени и декларирования проекта как
"быстро, бюджетно, здесь и сейчас" я остановился на принципе Кимбалла.

Кроме того, якорная модель мной уже подробно изучена в одном из ДЗ,
где я применил ее к google bigquery.

====== Локальный запуск спарка

Очень хотел запустить спарковую джобу на quickstart.cloudera на yarn, но
там старый спарк 1.6 и ява 1.7 (на них работает клаудеровский контейнер).

Если на спарк 1.6 я еще перевел, то установить яву 1.7 на свою ОС
мне не удалось по причине того, что нужно много чего даунгрейдить,
она как-то плохо уживается вместе с явой 1.8 и выше.

Потратил много времени, безуспешно пытаясь это все побороть.

В итоге решил запускать спарк локально в самом контейнере стримсета
(туда я пробросил каталог со спарком 2.4.4).

==== Золотой слой или витрины

Витрины у нас фактически лежат в серебряном слое, по методу Кимбалла,
это, конечно, сильно упрощенный вариант.

Поэтому витрины золотого слоя, datamart, которые видит непосредственно клиент,
по задумке этого проекта предполагают быть в виде представлений или просто
запросов к тем витринам, что лежат в хранилище данных.

=== Оркестрация

Оркестрация реализована при помощи Streamsets, который управляет

* Запуском основных потоков (пайплайнов)
* Вызывает раз в две секунды API источника для выкачки информации
* Событиями, которыа генерируются для вызова спарковой джобы (перекачка в сильвер-слой)
* Слушателем, который запускает по событиям выше спарковую джобу

=== Мониторинг

Функции мониторинга также может взять на себя Streamsets.

В процессе работы над проектом я запрограммировал его на запись различных
текстовых журналов, которые можно мониторить при помощи внешней системы типа того же ELK

Однако сам Streamsets очень хорошо и наглядно позволяет мониторить все этапы
по кр. мере бронзового слоя, начиная от обращения к источнику и заканчивая
укладкой данных в бронзовый слой и вызовом спарковой джобы для перекачки в сильвер.

На всех этих этапах видно, когда происходят ошибки и что-то ломается, видна
пропускная способность каждого этапа, количество переданных/принятых данных,
их перцентиль и прочее. +
Все это отлично визуализировано.

== Содержимое проекта

=== Streamsets

=== Cloudera

=== Spark

==== Job для загрузки в сильвер-слой.

[source, scala]
----
includee::jsonprocessor/src/main/scala/JsonProcessor.scala
----

== Примечания

=== Установка и разовая настройка

==== Клонируем репозиторий

Чтобы не грузить репозиторий гита, я смапил стейджы (библиотеки) streamsets в каталог `~/sdc-stagelibs`
(хотя, можно было включить в .gitignore, но уже поздно, сделал так, а проект сдавать :))

==== Каталоги

Необходим каталог `~/sdc-stagelibs`. +
Взять у меня или создать. Если создать, то ниже будет рассказано как его заполнить.

Необходим каталог `~/spark-2.4.4-bin-hadoop2.7` +
Скачать или взять у меня.

==== Права

Перейти в каталог гитового репозитория

[source, bash]
----
chmod 777 -R ~/sdc-stagelibs
chmod 777 -R project/sdc-data
chmod 777 -R project/sdc-stagelibs
chmod 777 -R project/shared_cloudera_quickstart
----

==== Запуск

`docker-compose up`

==== Разовая донастройка

Если до этого содержимое каталога `~/sdc-stagelibs` не было получено, то:

* Открыть в streamsets все пайплайны
* На какие стейджы стримсетс будет ругаться что отсутствует:
**  доустановить (меню пакетов в стримсетс), это разово, они потом сохраняться в
  `~/sdc-stagelibs`

==== Иоформация

Streamsets info

* location locahost: 18630
* credentials
** admin/admin

cloudera-quickstart info

* credentials
** claudera manager: admin/admin
** hue: claudera/claudera
* versions
** CDH 5.7.0
** Hadoop 2.6.0
** Hive 1.1.0

