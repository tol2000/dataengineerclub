= Домашнее задание №2

== Постановка задачи

[source]
----
Строим свою архитектуру
Цель: В данном домашнем задании от участников курса ожидается небольшой архитектурный документ ( желательно - не более 3-х страниц).

Выберите интересный сервис (Twitter / Uber / Linkedin / ваша организация или собственный проект) и разработайте для него архитектуру аналитического хранилища данных.

Опишите возможные требования к хранилищу, источники и архитектуру хранения.

Приведите пример бизнес-кейса, который можно решить с помощью выбранной вами архитектуры.
В решении обязательно должна присутствовать архитектурная схема вашего решения, которая должна объяснять откуда к вам поступают данные, как вы планируете их хранить и как вы планируете их отдавать для решения бизнес-кейса.
Описание архитектуры - это стандартное задание на архитектурных собеседованиях для Data Engineer.
Выполнив данное задание, вы сможете в будущем воспользоваться этими знаниями для того, чтобы качественно и продуманно создавать дизайн для аналитического хранилища данных или понимать как ваше data-driven приложение ложится в экосистему вашей организации. 

Для рисования схемы советуем использовать бесплатный сервис draw.io
Разместите ответ в виде документа Google Docs и поделитесь ссылкой.

Критерии оценки:
1.Факт свершения действия - архитектурный документ предоставлен на ревью
+1 балл

2. Степень выполнения ДЗ
+1 баллов – бизнес-кейс не описан, но приведены источники данных и разработана архитектура и описана архитектурная схема
+2 балла – источники и бизнес-кейс описаны, разработана архитектура и приведена архитектурная схема

3. Способ выполнения ДЗ
+1 балл – документ выполнен качественно, но архитектурная схема недостаточно детальна
+2 балл -- документ выполнен качественно, архитектурная схема содержит детальное описание процесса

Рекомендуем сдать до: 08.12.2019
----

== Решение

=== Компания убер, аналитическое хранилище для сбора информации по заказам.

В это хранилище будут поступать и там храниться данные по заказам
от всех автомобилей, зарегистрированных в Убер.

==== Аналитическое хранилище данных

===== Требования

* 1. Хранение исторических данных за большой промежуток времени (10 лет и более)
* 2. Быстрый доступ к информации за последнюю неделю для ежедневного планирования
* 3. Доступ к остальной информации в режиме заказа отчетов (заказал сейчас, получил через какое-то время)

===== Источники

* Данные от OLTP-БД: заказы на поездки
  ** Ключевая информация
     *** Номер заказа
     *** номер автомобиля (+код страны)
     *** timestamp заказа)
  ** Остальная информация по заказу
     *** информация от системы геолокации +
         может быть различной в зависимости от используемых аппаратных средств (gps, glonass...)
     *** остальное +
         (может добавляться или меняться со временем и развитием компании)

===== Архитектура хранения

Архитектуру выбираем типа Data Lake, поскольку будем хранить всю слабоструктурированную информация о заказах на нижнем уровне, парсить и преобразовывать ее на среднем и отдавать в виде решений для бизнес-кейсов на витрины.

image:http://www.plantuml.com/plantuml/svg/dLLDQ-jM4DthLmnP9GPlkYubBTqrq2v2DtKGSdJzGMJ9I399A874eKrBGqFRb4AWQL_WxMN7UjRBXzvVkFf7xzpnTMHBYZ5F8CkwCtFEd9cvLzj1QFdXeESOmK7NxLk-rIDRjAo14-wAe_1BfzjsUy8DQHy_mb_mShrGLBeOisT7M3RUEbvFa3WI_dut4FIP8LnRMmn7jF56eTSdHxH2GxxDJcKadsKY7sMI_IfZaXDUUCv-otwYR0ZB1ndHrrPeqOvr81JQ30MiZZUmQKFUmYLMGEm-HdIKNT6tExlVaVn3NfDyaAbyKZZCb6oG5P3dX7tJyv5MODfD-j4mJWoZ1Pa2YEMqofamIX1wleebNFFWFn4o142YHBnucNOFZgGl6oXDAr3k_yjOFcPNsSy8IC79sNFY3PUZxQQft7leMex0rm_o3ccEL988Zr0xXKG0V8Tx0gYOov7AUvasNEJ_E9E5x59O-ByA62CK_ywuaCFiGfKJRwfkx_TUSkWwnsRViLmJkJjYTIPJl3xWdkRTv0HIP7Y9LQP7KQ4TznF9LFCEbMdEoVqHjkcBlkU7GO7unE3VvUhVoX4tRwGGv-JvNF5BtXJiXRRuzBxey7LB0MN4IJsWk0dg0HDnboPCzlkIxi0y5E9W7SrlKDxJ5Ifzwr09gzR9E-HEJ_StuhZ-lUKCn5mXGelwQhML2ckrXWiNbZQ6pbWzJbMJiojbg-DYZnkbEBjGQ_AQXo4Ydf0OmHC0gWhzoriNuxWqKZ3y9LE0F-Vc23H37lCRB4ueE-DT6AbYBB1UvmMQC-SpSWzkJ2Xk477d4-M2ufx3bXGAl9VNI7UirAp5RctMQbzPuNw7QVy1p3tZJXNNqh77icFUVxnTr9DOobHlrHYEbrjCpxkogN1DnxFi2Yhi2AxJ6C8Gg6Gqt8eD3TU_YmT7pg7yD8ylMhu8EkjHBROKPQqO-bTvUVoNAK78do7ok-rEI5whqabVTMBEaOoM4j8Pyg58M9dYHmqB1kg2NT2F1Goq2BrPZ1z34v_lc6aT4EjPPqm6Yz3SNx2UAvK9emhNPWcwV3m9FDQhpaVOyWCoukeC0k7hWt4sVNF0_nZa7Cuwu_M1yPQK1HSyk68ZEIcSsQMasY8qRU48BRNunQtNlw3DulXkiMTvcRshjXhxLnXcyENXO89A0qTKdhshEKfzO8ggTVPV-LNRhAxV5drUhxyUoQ5LcUiQLszVJlDrAyTMVVQD4sCRCppeEHy1[Схема]



===== Аналитические отчеты






Нам важно не нагружать сильно БД источника, поэтому

* если БД источника будет что-то вроде Оракла, то можем забирать просто архивные журналы
  транзакций (архивлоги)  и накатывать их у себя в какой-нибудь промежуточной оракловой БД,
  а затем перемещать в более подходящую БД либо оставлять в Оракле. +
  Это вообще не будет давать никакой дополнительной нагрузки на БД источника.

* В другом случае можно просто несколько раз в сутки максимально быстро выкачивать информацию за определенный период без какой-либо сложной нагрузки на БД источника.

===== 3. Архитектура хранения

Если данные сугубо с нмеа, тогда дата лейк норм, сырые там, все такое...
Если как описал в последнее время, то.....

Архитектура типа Data Lake

* Нижний слой, сырые данные +
  Получаем согласно предыдущему подразделу 2 (Источники)
* Средний слой +
  Здесь мы сырые данные в формате NMEA парсим, выделяем координаты, высчитываем локальное время, скорость, идентифицируем транспортное средство, связываем со справочниками, возможно, преобразуем в форматы гугл мапс и пр.
* Верхний слой, дата март +
  Различные витрины
  ** Логистические отчеты за сутки для планирования загрузок
  ** Витрины статистических отчетов за месяц, год по пробегу, расходу топлива, средней скорости,
     охвату территории, пересечению границ и пр.
  ** Заказные отчеты по требованиям клиентов в их личных кабинетах +
     клиент заказывает отчет, он считается и поступает клиенту через какое-то время

===== Пример бизнес-кейса

* 1. Распределение плотности заказов по районам за последнюю неделю
* 2. Статистика заказов по будням и выходным за год
* 3. Статистика заказов на новогодние праздники за последние 10 лет